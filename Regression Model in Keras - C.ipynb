{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression model in Keras\n",
    "## A - Build a baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data = pd.read_csv('https://cocl.us/concrete_data')\n",
    "concrete_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement                0\n",
       "Blast Furnace Slag    0\n",
       "Fly Ash               0\n",
       "Water                 0\n",
       "Superplasticizer      0\n",
       "Coarse Aggregate      0\n",
       "Fine Aggregate        0\n",
       "Age                   0\n",
       "Strength              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data_columns = concrete_data.columns\n",
    "\n",
    "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\n",
    "target = concrete_data['Strength'] # Strength column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  \n",
       "0            1040.0           676.0   28  \n",
       "1            1055.0           676.0   28  \n",
       "2             932.0           594.0  270  \n",
       "3             932.0           594.0  365  \n",
       "4             978.4           825.5  360  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    79.99\n",
       "1    61.89\n",
       "2    40.27\n",
       "3    41.05\n",
       "4    44.30\n",
       "Name: Strength, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = predictors.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly split the data into a training and test sets by holding 30% of the data for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional step for B: normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>0.862735</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>1.055651</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>3.551340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>5.055221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.790075</td>\n",
       "      <td>0.678079</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>0.488555</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>0.647569</td>\n",
       "      <td>4.976069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
       "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate       Age  \n",
       "0          0.862735       -1.217079 -0.279597  \n",
       "1          1.055651       -1.217079 -0.279597  \n",
       "2         -0.526262       -2.239829  3.551340  \n",
       "3         -0.526262       -2.239829  5.055221  \n",
       "4          0.070492        0.647569  4.976069  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
    "predictors_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shapes: (721, 8) (721,)\n",
      "Testing set shapes: (309, 8) (309,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3, random_state=42)\n",
    "print('Training set shapes: {} {}'.format(X_train.shape, y_train.shape))\n",
    "print('Testing set shapes: {} {}'.format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a neural network\n",
    "\n",
    "Characteristics:\n",
    "\n",
    "* One hidden layer of 10 nodes, and a ReLU activation function\n",
    "* Use the **adam** optimizer and the **mean squared error**  as the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_regression_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = baseline_regression_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case C: Train the model on the normalized training data using 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 504 samples, validate on 217 samples\n",
      "Epoch 1/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 1650.0044 - val_loss: 1519.0872\n",
      "Epoch 2/100\n",
      "504/504 [==============================] - 0s 505us/step - loss: 1640.5489 - val_loss: 1509.9177\n",
      "Epoch 3/100\n",
      "504/504 [==============================] - 0s 648us/step - loss: 1631.2608 - val_loss: 1500.9365\n",
      "Epoch 4/100\n",
      "504/504 [==============================] - 0s 619us/step - loss: 1622.1750 - val_loss: 1492.0116\n",
      "Epoch 5/100\n",
      "504/504 [==============================] - 0s 629us/step - loss: 1613.1817 - val_loss: 1482.8848\n",
      "Epoch 6/100\n",
      "504/504 [==============================] - 0s 784us/step - loss: 1603.9537 - val_loss: 1473.8200\n",
      "Epoch 7/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 1594.7260 - val_loss: 1464.4997\n",
      "Epoch 8/100\n",
      "504/504 [==============================] - 0s 754us/step - loss: 1585.2917 - val_loss: 1454.9409\n",
      "Epoch 9/100\n",
      "504/504 [==============================] - 0s 788us/step - loss: 1575.6320 - val_loss: 1444.9131\n",
      "Epoch 10/100\n",
      "504/504 [==============================] - 0s 871us/step - loss: 1565.3943 - val_loss: 1434.7143\n",
      "Epoch 11/100\n",
      "504/504 [==============================] - 0s 953us/step - loss: 1554.8365 - val_loss: 1423.9761\n",
      "Epoch 12/100\n",
      "504/504 [==============================] - 0s 514us/step - loss: 1543.8129 - val_loss: 1412.5565\n",
      "Epoch 13/100\n",
      "504/504 [==============================] - 0s 663us/step - loss: 1532.2825 - val_loss: 1400.6041\n",
      "Epoch 14/100\n",
      "504/504 [==============================] - 0s 564us/step - loss: 1520.1475 - val_loss: 1388.2940\n",
      "Epoch 15/100\n",
      "504/504 [==============================] - 0s 681us/step - loss: 1507.4305 - val_loss: 1375.5411\n",
      "Epoch 16/100\n",
      "504/504 [==============================] - 0s 584us/step - loss: 1494.4633 - val_loss: 1362.0064\n",
      "Epoch 17/100\n",
      "504/504 [==============================] - 0s 597us/step - loss: 1480.6353 - val_loss: 1348.0086\n",
      "Epoch 18/100\n",
      "504/504 [==============================] - 0s 676us/step - loss: 1466.4008 - val_loss: 1333.5829\n",
      "Epoch 19/100\n",
      "504/504 [==============================] - 0s 598us/step - loss: 1451.6103 - val_loss: 1318.6959\n",
      "Epoch 20/100\n",
      "504/504 [==============================] - 0s 730us/step - loss: 1436.5169 - val_loss: 1303.1015\n",
      "Epoch 21/100\n",
      "504/504 [==============================] - 0s 647us/step - loss: 1420.4862 - val_loss: 1287.4513\n",
      "Epoch 22/100\n",
      "504/504 [==============================] - 0s 564us/step - loss: 1404.3333 - val_loss: 1271.1060\n",
      "Epoch 23/100\n",
      "504/504 [==============================] - 0s 597us/step - loss: 1387.1649 - val_loss: 1254.6464\n",
      "Epoch 24/100\n",
      "504/504 [==============================] - 0s 512us/step - loss: 1370.0733 - val_loss: 1236.9261\n",
      "Epoch 25/100\n",
      "504/504 [==============================] - 0s 558us/step - loss: 1351.8861 - val_loss: 1219.2203\n",
      "Epoch 26/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 1333.4401 - val_loss: 1201.2229\n",
      "Epoch 27/100\n",
      "504/504 [==============================] - 0s 675us/step - loss: 1314.9216 - val_loss: 1182.0281\n",
      "Epoch 28/100\n",
      "504/504 [==============================] - 0s 668us/step - loss: 1294.9454 - val_loss: 1163.4060\n",
      "Epoch 29/100\n",
      "504/504 [==============================] - 0s 590us/step - loss: 1275.1940 - val_loss: 1143.7966\n",
      "Epoch 30/100\n",
      "504/504 [==============================] - 0s 480us/step - loss: 1254.5599 - val_loss: 1124.2669\n",
      "Epoch 31/100\n",
      "504/504 [==============================] - 0s 866us/step - loss: 1233.6128 - val_loss: 1104.4806\n",
      "Epoch 32/100\n",
      "504/504 [==============================] - 0s 625us/step - loss: 1212.2699 - val_loss: 1084.3134\n",
      "Epoch 33/100\n",
      "504/504 [==============================] - 0s 479us/step - loss: 1190.5633 - val_loss: 1063.6481\n",
      "Epoch 34/100\n",
      "504/504 [==============================] - 0s 756us/step - loss: 1168.3960 - val_loss: 1043.0778\n",
      "Epoch 35/100\n",
      "504/504 [==============================] - 0s 696us/step - loss: 1145.3587 - val_loss: 1022.6444\n",
      "Epoch 36/100\n",
      "504/504 [==============================] - 0s 671us/step - loss: 1122.7189 - val_loss: 1001.6968\n",
      "Epoch 37/100\n",
      "504/504 [==============================] - 0s 400us/step - loss: 1099.6780 - val_loss: 980.3588\n",
      "Epoch 38/100\n",
      "504/504 [==============================] - 0s 465us/step - loss: 1076.1127 - val_loss: 959.0474\n",
      "Epoch 39/100\n",
      "504/504 [==============================] - 0s 676us/step - loss: 1052.2605 - val_loss: 937.9995\n",
      "Epoch 40/100\n",
      "504/504 [==============================] - 0s 398us/step - loss: 1029.3695 - val_loss: 916.3353\n",
      "Epoch 41/100\n",
      "504/504 [==============================] - 0s 476us/step - loss: 1004.7359 - val_loss: 895.8956\n",
      "Epoch 42/100\n",
      "504/504 [==============================] - 0s 717us/step - loss: 981.9875 - val_loss: 874.4301\n",
      "Epoch 43/100\n",
      "504/504 [==============================] - 0s 479us/step - loss: 957.8999 - val_loss: 853.8575\n",
      "Epoch 44/100\n",
      "504/504 [==============================] - 0s 426us/step - loss: 934.6689 - val_loss: 833.2649\n",
      "Epoch 45/100\n",
      "504/504 [==============================] - 0s 453us/step - loss: 911.2047 - val_loss: 813.2247\n",
      "Epoch 46/100\n",
      "504/504 [==============================] - ETA: 0s - loss: 893.703 - 0s 394us/step - loss: 888.5382 - val_loss: 793.0689\n",
      "Epoch 47/100\n",
      "504/504 [==============================] - 0s 433us/step - loss: 866.0929 - val_loss: 773.0208\n",
      "Epoch 48/100\n",
      "504/504 [==============================] - 0s 553us/step - loss: 842.9833 - val_loss: 754.3208\n",
      "Epoch 49/100\n",
      "504/504 [==============================] - 0s 638us/step - loss: 821.8654 - val_loss: 734.7524\n",
      "Epoch 50/100\n",
      "504/504 [==============================] - 0s 861us/step - loss: 800.0036 - val_loss: 716.1959\n",
      "Epoch 51/100\n",
      "504/504 [==============================] - 0s 437us/step - loss: 778.7697 - val_loss: 698.0279\n",
      "Epoch 52/100\n",
      "504/504 [==============================] - 0s 441us/step - loss: 758.6260 - val_loss: 679.9799\n",
      "Epoch 53/100\n",
      "504/504 [==============================] - 0s 436us/step - loss: 738.3191 - val_loss: 662.7836\n",
      "Epoch 54/100\n",
      "504/504 [==============================] - 0s 406us/step - loss: 718.4844 - val_loss: 646.3843\n",
      "Epoch 55/100\n",
      "504/504 [==============================] - 0s 450us/step - loss: 700.1591 - val_loss: 629.4372\n",
      "Epoch 56/100\n",
      "504/504 [==============================] - 0s 433us/step - loss: 681.1331 - val_loss: 613.4739\n",
      "Epoch 57/100\n",
      "504/504 [==============================] - 0s 479us/step - loss: 663.1182 - val_loss: 598.0093\n",
      "Epoch 58/100\n",
      "504/504 [==============================] - 0s 443us/step - loss: 645.6937 - val_loss: 582.7433\n",
      "Epoch 59/100\n",
      "504/504 [==============================] - 0s 367us/step - loss: 628.6734 - val_loss: 568.0606\n",
      "Epoch 60/100\n",
      "504/504 [==============================] - 0s 430us/step - loss: 612.1213 - val_loss: 554.0299\n",
      "Epoch 61/100\n",
      "504/504 [==============================] - 0s 429us/step - loss: 596.0178 - val_loss: 540.3571\n",
      "Epoch 62/100\n",
      "504/504 [==============================] - 0s 441us/step - loss: 580.7222 - val_loss: 527.0754\n",
      "Epoch 63/100\n",
      "504/504 [==============================] - 0s 473us/step - loss: 565.8261 - val_loss: 514.3472\n",
      "Epoch 64/100\n",
      "504/504 [==============================] - 0s 463us/step - loss: 551.4808 - val_loss: 502.1340\n",
      "Epoch 65/100\n",
      "504/504 [==============================] - 0s 485us/step - loss: 538.0463 - val_loss: 489.8953\n",
      "Epoch 66/100\n",
      "504/504 [==============================] - 0s 434us/step - loss: 524.2394 - val_loss: 478.7009\n",
      "Epoch 67/100\n",
      "504/504 [==============================] - ETA: 0s - loss: 513.660 - 0s 371us/step - loss: 511.9028 - val_loss: 467.3382\n",
      "Epoch 68/100\n",
      "504/504 [==============================] - 0s 402us/step - loss: 499.2886 - val_loss: 456.9235\n",
      "Epoch 69/100\n",
      "504/504 [==============================] - 0s 434us/step - loss: 487.5489 - val_loss: 446.6827\n",
      "Epoch 70/100\n",
      "504/504 [==============================] - 0s 506us/step - loss: 476.1744 - val_loss: 436.6748\n",
      "Epoch 71/100\n",
      "504/504 [==============================] - 0s 408us/step - loss: 465.4334 - val_loss: 426.8479\n",
      "Epoch 72/100\n",
      "504/504 [==============================] - 0s 476us/step - loss: 454.6231 - val_loss: 417.7892\n",
      "Epoch 73/100\n",
      "504/504 [==============================] - 0s 474us/step - loss: 444.7426 - val_loss: 408.7168\n",
      "Epoch 74/100\n",
      "504/504 [==============================] - 0s 448us/step - loss: 434.9386 - val_loss: 400.0992\n",
      "Epoch 75/100\n",
      "504/504 [==============================] - 0s 479us/step - loss: 425.7711 - val_loss: 391.6557\n",
      "Epoch 76/100\n",
      "504/504 [==============================] - 0s 430us/step - loss: 416.5825 - val_loss: 383.8219\n",
      "Epoch 77/100\n",
      "504/504 [==============================] - 0s 395us/step - loss: 408.0154 - val_loss: 376.1973\n",
      "Epoch 78/100\n",
      "504/504 [==============================] - 0s 470us/step - loss: 399.9982 - val_loss: 368.5041\n",
      "Epoch 79/100\n",
      "504/504 [==============================] - 0s 523us/step - loss: 391.7997 - val_loss: 361.3664\n",
      "Epoch 80/100\n",
      "504/504 [==============================] - 0s 504us/step - loss: 384.3420 - val_loss: 354.2433\n",
      "Epoch 81/100\n",
      "504/504 [==============================] - 0s 401us/step - loss: 376.6924 - val_loss: 347.6816\n",
      "Epoch 82/100\n",
      "504/504 [==============================] - 0s 471us/step - loss: 369.4711 - val_loss: 341.2242\n",
      "Epoch 83/100\n",
      "504/504 [==============================] - 0s 433us/step - loss: 362.4930 - val_loss: 334.5839\n",
      "Epoch 84/100\n",
      "504/504 [==============================] - 0s 399us/step - loss: 355.4934 - val_loss: 328.2090\n",
      "Epoch 85/100\n",
      "504/504 [==============================] - 0s 426us/step - loss: 348.4509 - val_loss: 321.9590\n",
      "Epoch 86/100\n",
      "504/504 [==============================] - 0s 444us/step - loss: 341.4530 - val_loss: 315.8141\n",
      "Epoch 87/100\n",
      "504/504 [==============================] - 0s 432us/step - loss: 334.7426 - val_loss: 309.2145\n",
      "Epoch 88/100\n",
      "504/504 [==============================] - 0s 481us/step - loss: 327.7863 - val_loss: 302.8356\n",
      "Epoch 89/100\n",
      "504/504 [==============================] - 0s 426us/step - loss: 320.8683 - val_loss: 296.5967\n",
      "Epoch 90/100\n",
      "504/504 [==============================] - 0s 469us/step - loss: 314.0109 - val_loss: 290.3942\n",
      "Epoch 91/100\n",
      "504/504 [==============================] - 0s 479us/step - loss: 307.3677 - val_loss: 283.9932\n",
      "Epoch 92/100\n",
      "504/504 [==============================] - 0s 512us/step - loss: 300.8186 - val_loss: 277.4619\n",
      "Epoch 93/100\n",
      "504/504 [==============================] - 0s 442us/step - loss: 293.9654 - val_loss: 271.7896\n",
      "Epoch 94/100\n",
      "504/504 [==============================] - 0s 402us/step - loss: 287.7357 - val_loss: 265.8872\n",
      "Epoch 95/100\n",
      "504/504 [==============================] - 0s 467us/step - loss: 281.4054 - val_loss: 260.1819\n",
      "Epoch 96/100\n",
      "504/504 [==============================] - 0s 479us/step - loss: 275.5702 - val_loss: 254.4585\n",
      "Epoch 97/100\n",
      "504/504 [==============================] - 0s 550us/step - loss: 269.5711 - val_loss: 249.0799\n",
      "Epoch 98/100\n",
      "504/504 [==============================] - 0s 444us/step - loss: 263.8477 - val_loss: 244.1221\n",
      "Epoch 99/100\n",
      "504/504 [==============================] - 0s 487us/step - loss: 258.7280 - val_loss: 238.8808\n",
      "Epoch 100/100\n",
      "504/504 [==============================] - 0s 463us/step - loss: 253.3393 - val_loss: 234.0643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f995759d978>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_split=0.3, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on the normalized test data\n",
    "Compute the mean squared error between the predicted concrete strength and the actual concrete strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 257.0532\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "yhat = model.predict(X_test)\n",
    "print(\"MSE: %.4f\" % mean_squared_error(y_test , yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat splitting, training (100 epochs) and evaluation 50 times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of 50 MSE (don't forget to normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #1 --- MSE: 185.7539\n",
      "Iteration #2 --- MSE: 210.4115\n",
      "Iteration #3 --- MSE: 186.6906\n",
      "Iteration #4 --- MSE: 258.3781\n",
      "Iteration #5 --- MSE: 211.6799\n",
      "Iteration #6 --- MSE: 194.6441\n",
      "Iteration #7 --- MSE: 190.4132\n",
      "Iteration #8 --- MSE: 160.7081\n",
      "Iteration #9 --- MSE: 170.5617\n",
      "Iteration #10 --- MSE: 218.6364\n",
      "Iteration #11 --- MSE: 376.9723\n",
      "Iteration #12 --- MSE: 192.3379\n",
      "Iteration #13 --- MSE: 172.3439\n",
      "Iteration #14 --- MSE: 230.3449\n",
      "Iteration #15 --- MSE: 174.4106\n",
      "Iteration #16 --- MSE: 182.2627\n",
      "Iteration #17 --- MSE: 246.1698\n",
      "Iteration #18 --- MSE: 179.4448\n",
      "Iteration #19 --- MSE: 274.6804\n",
      "Iteration #20 --- MSE: 180.8967\n",
      "Iteration #21 --- MSE: 182.7673\n",
      "Iteration #22 --- MSE: 190.4786\n",
      "Iteration #23 --- MSE: 205.6154\n",
      "Iteration #24 --- MSE: 256.4773\n",
      "Iteration #25 --- MSE: 186.7124\n",
      "Iteration #26 --- MSE: 196.0078\n",
      "Iteration #27 --- MSE: 232.7243\n",
      "Iteration #28 --- MSE: 210.6033\n",
      "Iteration #29 --- MSE: 202.0420\n",
      "Iteration #30 --- MSE: 304.4335\n",
      "Iteration #31 --- MSE: 174.1629\n",
      "Iteration #32 --- MSE: 206.0711\n",
      "Iteration #33 --- MSE: 206.9637\n",
      "Iteration #34 --- MSE: 416.2824\n",
      "Iteration #35 --- MSE: 195.2157\n",
      "Iteration #36 --- MSE: 179.0028\n",
      "Iteration #37 --- MSE: 187.9432\n",
      "Iteration #38 --- MSE: 222.1056\n",
      "Iteration #39 --- MSE: 191.3089\n",
      "Iteration #40 --- MSE: 244.0601\n",
      "Iteration #41 --- MSE: 202.1839\n",
      "Iteration #42 --- MSE: 247.2491\n",
      "Iteration #43 --- MSE: 208.6654\n",
      "Iteration #44 --- MSE: 287.1163\n",
      "Iteration #45 --- MSE: 241.5059\n",
      "Iteration #46 --- MSE: 186.7391\n",
      "Iteration #47 --- MSE: 178.9737\n",
      "Iteration #48 --- MSE: 168.1520\n",
      "Iteration #49 --- MSE: 197.5902\n",
      "Iteration #50 --- MSE: 208.7082\n"
     ]
    }
   ],
   "source": [
    "mse_list = list()\n",
    "\n",
    "for i in range(50):\n",
    "    # Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3, random_state=42)\n",
    "    # Compile and train the model\n",
    "    model = baseline_regression_model()\n",
    "    model.fit(X_train, y_train, validation_split=0.3, epochs=100, verbose=0)\n",
    "    # Predict based on test set and calculate MSE\n",
    "    yhat = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test , yhat)\n",
    "    mse_list.append(mse)\n",
    "    print(\"Iteration #%d --- MSE: %.4f\" % (i+1, mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report the mean and the standard deviation of the mean squared errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of MSE: 214.3121\n",
      "Standard deviation of MSE: 48.8012\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean of MSE: %.4f\" % np.mean(mse_list))\n",
    "print(\"Standard deviation of MSE: %.4f\" % np.std(mse_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean of MSE for 100 epochs (214.3121) was ~3 times lower than mean MSE from case B (652.7311)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
